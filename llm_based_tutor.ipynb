{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe12c203-e6a6-452c-a655-afb8a03a4ff5",
   "metadata": {},
   "source": [
    "# LLM Based Tutor\n",
    "\n",
    "This tool enables users to generate detailed explanations for technical questions using OpenAI’s GPT or LLAMA models. It provides a streamlined approach to accessing AI-driven insights and enhancing understanding of complex topics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1070317-3ed9-4659-abe3-828943230e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary modules\n",
    "import os               # Provides functions for interacting with the operating system\n",
    "import ollama                  # Library for interacting with the Ollama AI model\n",
    "from dotenv import load_dotenv  # Loads environment variables from a .env file\n",
    "from openai import OpenAI        # Interface for OpenAI API\n",
    "from IPython.display import Markdown, display, update_display  # Provides enhanced display for Jupyter/IPython environments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a456906-915a-4bfd-bb9d-57e505c5093f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants for model selection\n",
    "MODEL_GPT = 'gpt-4o-mini'        # Specify the GPT model version\n",
    "MODEL_LLAMA = 'llama3.2'         # Specify the LLAMA model version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f0d0137-52b0-47a8-81a8-11a90a010798",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example question for the tool (change this to ask anything new)\n",
    "question = \"\"\"\n",
    "Please explain what this code does and why:\n",
    "result = {f\"{item.get('name')} ({item.get('category')})\": item.get('price') for item in inventory if item.get('price') and item.get('category')}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7c40870-a0fa-4b34-b92f-b31f135e1158",
   "metadata": {},
   "outputs": [],
   "source": [
    "# System prompt for OpenAI or LLAMA\n",
    "system_prompt = \"\"\"\n",
    "You are a knowledgeable technical tutor who provides detailed explanations and guidance on topics such as Python programming, \n",
    "software engineering, data science, and large language models (LLMs). \n",
    "Your responses should be clear, concise, and tailored to the user's level of understanding.\n",
    "\"\"\"\n",
    "\n",
    "# User prompt preparation\n",
    "def user_prompt(question):\n",
    "    \"\"\"\n",
    "    Prepares the user prompt with a given question.\n",
    "    \n",
    "    Args:\n",
    "    - question (str): The technical question for explanation.\n",
    "\n",
    "    Returns:\n",
    "    - str: Formatted prompt for AI.\n",
    "    \"\"\"\n",
    "    user_prompt = \"Could you provide a detailed explanation for the following question: \\n\"\n",
    "    user_prompt += question\n",
    "    return user_prompt\n",
    "\n",
    "# Prompt list containing system and user roles\n",
    "the_prompts = [{\"role\": \"system\", \"content\": system_prompt},\n",
    "               {\"role\": \"user\", \"content\": user_prompt(question)}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60ce7000-a4a5-4cce-a261-e75ef45063b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up environment for using GPT model\n",
    "load_dotenv()                        # Load environment variables from .env file\n",
    "openai = OpenAI()                    # Initialize OpenAI client\n",
    "\n",
    "# Initialize OpenAI client with API key\n",
    "openai.api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "# Function to get GPT-4o-mini to answer\n",
    "def gpt_answer(the_prompts):\n",
    "    \"\"\"\n",
    "    Generates a response from GPT-4o-mini model using streaming.\n",
    "\n",
    "    Args:\n",
    "    - the_prompts (list): List containing system and user prompts.\n",
    "\n",
    "    Returns:\n",
    "    - None: Updates the Jupyter display dynamically.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        stream = openai.chat.completions.create(\n",
    "            model=MODEL_GPT,\n",
    "            messages=the_prompts,\n",
    "            stream=True  # Enable streaming mode for dynamic output\n",
    "        )\n",
    "\n",
    "        response = \"\"\n",
    "        display_handle = display(Markdown(\"\"), display_id=True)  # Display placeholder Markdown in Jupyter/IPython\n",
    "        for chunk in stream:\n",
    "            response += chunk.choices[0].delta.content or \"\"\n",
    "            response = response.replace(\"```\",\"\").replace(\"markdown\", \"\")  # Clean up Markdown formatting\n",
    "            update_display(Markdown(response), display_id=display_handle.display_id)  # Update display dynamically\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while streaming the answer for your question: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f7c8ea8-4082-4ad0-8751-3301adcf6538",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get LLAMA 3.2 to answer\n",
    "def llama_answer(the_prompts):\n",
    "    \"\"\"\n",
    "    Generates a response from LLAMA 3.2 model using streaming.\n",
    "\n",
    "    Args:\n",
    "    - the_prompts (list): List containing system and user prompts.\n",
    "\n",
    "    Returns:\n",
    "    - None: Updates the Jupyter display dynamically.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        stream = ollama.chat(\n",
    "            model=MODEL_LLAMA,\n",
    "            messages=the_prompts,\n",
    "            stream=True  # Enable streaming mode for dynamic output\n",
    "        )\n",
    "\n",
    "        response = \"\"\n",
    "        display_handle = display(Markdown(\"\"), display_id=True)  # Display placeholder Markdown in Jupyter/IPython\n",
    "        for chunk in stream:\n",
    "            response += chunk[\"message\"][\"content\"] or \"\"\n",
    "            response = response.replace(\"```\",\"\").replace(\"markdown\", \"\")  # Clean up Markdown formatting\n",
    "            update_display(Markdown(response), display_id=display_handle.display_id)  # Update display dynamically\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while streaming the answer for your question: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2548ede7-bd68-49e3-967c-4b5f08c71068",
   "metadata": {},
   "source": [
    "### Testing GPT Model \"gpt-4o-mini\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "55d726ab-0c78-4261-abaf-8587d658bb7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Certainly! Let's break down the code you've provided step-by-step to understand what it does and why it works this way.\n",
       "\n",
       "### Explanation of the Code\n",
       "\n",
       "python\n",
       "result = {f\"{item.get('name')} ({item.get('category')})\": item.get('price') for item in inventory if item.get('price') and item.get('category')}\n",
       "\n",
       "\n",
       "1. **Context**: This code is using a dictionary comprehension to create a new dictionary called `result`. The dictionary is constructed from items in a collection named `inventory`.\n",
       "\n",
       "2. **Dictionary Comprehension**: \n",
       "   - The overall structure of the code indicates that a dictionary comprehension is being used. This is a concise way to create dictionaries in Python.\n",
       "   - It consists of a key-value pair separated by a colon (`:`) inside curly braces (`{}`).\n",
       "\n",
       "3. **Iterating Over `inventory`**:\n",
       "   - The code iterates over `inventory`, which is assumed to be a list (or another iterable) of dictionaries. Each dictionary represents an item with various attributes, such as `name`, `category`, and `price`.\n",
       "\n",
       "4. **Building Keys**:\n",
       "   - The key for each entry in the resulting dictionary is constructed using an f-string:\n",
       "     python\n",
       "     f\"{item.get('name')} ({item.get('category')})\"\n",
       "     \n",
       "     - `item.get('name')`: This retrieves the value associated with the key `'name'` from the current `item`.\n",
       "     - `item.get('category')`: This retrieves the value associated with the key `'category'`.\n",
       "     - The resulting string will look like \"item_name (item_category)\", allowing for a clear representation of the item paired with its category.\n",
       "\n",
       "5. **Building Values**:\n",
       "   - The value assigned to each key in the new dictionary is obtained by:\n",
       "     python\n",
       "     item.get('price')\n",
       "     \n",
       "     - This retrieves the price of the current item.\n",
       "\n",
       "6. **Filtering**:\n",
       "   - The `if` statement at the end of the comprehension is a filter that ensures only valid items are included in the resulting dictionary:\n",
       "     python\n",
       "     if item.get('price') and item.get('category')\n",
       "     \n",
       "     - This checks two conditions:\n",
       "       - `item.get('price')`: Checks if the price is present and truthy (not None or zero).\n",
       "       - `item.get('category')`: Checks if the category is present and truthy.\n",
       "     - If both conditions are met, the item is included in the dictionary; otherwise, it is skipped.\n",
       "\n",
       "### Summary\n",
       "\n",
       "- The **result** dictionary will contain keys formatted as `\"item_name (item_category)\"` paired with their corresponding price. Only items that have both a valid price and a valid category will be included. \n",
       "- The use of `.get()` is important here as it prevents `KeyError` exceptions if any of the keys (`'name'`, `'category'`, or `'price'`) do not exist in an item, as it returns None instead.\n",
       "\n",
       "This code is useful for creating a well-organized representation of items in an inventory, particularly when you want to quickly reference items by their name and category while tracking their prices."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Testing GPT Model \"gpt-4o-mini\"\n",
    "gpt_answer(the_prompts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72721c8e-6acf-4de1-af2d-bdc47edce2a1",
   "metadata": {},
   "source": [
    "### Testing LLAMA Model \"llama3.2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "35a23778-e896-4527-9768-eeb338aebdfb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Let's break down this line of code.\n",
       "\n",
       "**What is it doing?**\n",
       "\n",
       "This line of code uses a combination of Python features to create a new dictionary (an object that stores key-value pairs) called `result`. The resulting dictionary will contain only specific items from the `inventory` list, filtered based on certain conditions.\n",
       "\n",
       "Here's a step-by-step explanation:\n",
       "\n",
       "1. **List comprehension**: The code uses a feature called \"list comprehension\" which allows us to create lists or other iterables in a concise way.\n",
       "2. **Dictionary comprehension**: The line is using another type of feature called \"dictionary comprehension\", but with some additional twists.\n",
       "3. **Filtering**: We're only including items from the `inventory` list if they have both:\n",
       "   - A 'price' key\n",
       "   - A 'category' key\n",
       "\n",
       "Now, let's talk about what's inside the dictionary comprehension:\n",
       "\n",
       "* `{...}`: This is a dictionary literal, which creates an empty dictionary that we'll populate with values.\n",
       "* `f\"{item.get('name')} ({item.get('category')})\"`:\n",
       "\t+ We're creating a new string value for each item in the `inventory` list. The expression inside the curly braces uses another feature called \"format strings\" (introduced in Python 3.6).\n",
       "\t+ `item.get('name')` and `item.get('category')` access values from the dictionary stored in the `item`. If either of these keys don't exist, it will return `None`.\n",
       "\t+ The formatted string looks something like this: `“Product Name (Category)”`, where `Product Name` is the name of the item and `(Category)` is the category.\n",
       "* `.get('price')`: This accesses the value stored under the 'price' key in the same dictionary. Again, if this key doesn't exist, it will return `None`.\n",
       "\n",
       "**Putting it all together**\n",
       "\n",
       "The list comprehension iterates over each `item` in the `inventory`. If an item has both a 'price' and a 'category', its formatted string is used as a key in our new dictionary. The corresponding value (the price) is assigned to this key.\n",
       "\n",
       "Here's an example:\n",
       "python\n",
       "inventory = [\n",
       "    {'name': 'Apple', 'price': 1.00, 'category': 'Fruit'},\n",
       "    {'name': 'Banana', 'price': None},  # missing price key\n",
       "    {'name': 'Orange', 'price': 2.50, 'category': 'Fruit'},\n",
       "    {'name': 'Carrot', 'price': 0.75}  # no category key\n",
       "]\n",
       "\n",
       "result = {f\"{item.get('name')} ({item.get('category')})\": item.get('price') for item in inventory if item.get('price') and item.get('category')}\n",
       "print(result)\n",
       "\n",
       "This would produce an output like this:\n",
       "python\n",
       "{\n",
       "    \"Apple (Fruit)\": 1.0,\n",
       "    \"Orange (Fruit)\": 2.5\n",
       "}\n",
       "\n",
       "The `Banana` is not included because it doesn't have a price key, and the `Carrot` has no category key but does have a price.\n",
       "\n",
       "I hope this explanation helped clarify what's going on in that line of code!"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Testing LLAMA Model \"llama3.2\"\n",
    "llama_answer(the_prompts)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
